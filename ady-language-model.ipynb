{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:08:49.841957Z",
     "start_time": "2019-03-22T23:08:49.775021Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-22 23:08:49,822 : DEBUG : Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'; # adapt plots for retina displays\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid');\n",
    "sns.set_context(context='notebook');\n",
    "from typing import List\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import io\n",
    "import ftfy \n",
    "import re\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "from studio_client import Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:08:50.900718Z",
     "start_time": "2019-03-22T23:08:50.090151Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-22 23:08:50,741 : INFO : Initializing environment with Studio API: https://mlstudio.sapai.c.eu-de-1.cloud.sap:30001\n",
      "2019-03-22 23:08:50,858 : DEBUG : Loading latest version (1) for datasets/ady.txt from local.\n"
     ]
    }
   ],
   "source": [
    "env = Environment(project=\"dummy\",\n",
    "                  studio_endpoint=\"https://mlstudio.sapai.c.eu-de-1.cloud.sap:30001\") \n",
    "\n",
    "dataset_path = env.get_file('datasets/ady.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:08:53.759048Z",
     "start_time": "2019-03-22T23:08:50.905208Z"
    }
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "with io.open(dataset_path, mode='r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line =  ftfy.fix_text(line, normalization='NFKC')\n",
    "        line = line.replace('\\n', '')\n",
    "        line = re.sub(\"\\s\\s+\", \" \", line)\n",
    "        line = line.strip()\n",
    "        if len(line)<=2 : continue\n",
    "        text += [line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:08:53.783124Z",
     "start_time": "2019-03-22T23:08:53.761272Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ady Endre összes költeménye',\n",
       " 'ÚJ VERSEK – 1906',\n",
       " 'E versek mind–mind a Léda asszonyéi, aki kedvelte és akarta õket. Én el',\n",
       " 'szoktam pusztítani a verseimet fogyó életem növõ lázában, mély viharzásokon',\n",
       " 'és poklok tüzében. Ennek a néhány versnek megkegyelmeztem. Engedtem',\n",
       " 'õket életre jönni, s átnyújtom õket Léda asszonynak.',\n",
       " 'GÓG ÉS MAGÓG FIA VAGYOK ÉN...',\n",
       " 'Góg és Magóg fia vagyok én,',\n",
       " 'Hiába döngetek kaput, falat',\n",
       " 'S mégis megkérdem tõletek:',\n",
       " 'Szabad–e sírni a Kárpátok alatt?',\n",
       " 'Verecke híres útján jöttem én,',\n",
       " 'Fülembe még õsmagyar dal rivall,',\n",
       " 'Szabad–e Dévénynél betörnöm',\n",
       " 'Új idõknek új dalaival?',\n",
       " 'Fülembe forró ólmot öntsetek',\n",
       " 'Legyek az új, az énekes Vazul,',\n",
       " 'Ne halljam az élet új dalait,',\n",
       " 'Tiporjatok reám durván, gazul.',\n",
       " 'De addig sírva, kínban, mit se várva',\n",
       " 'Mégiscsak száll új szárnyakon a dal',\n",
       " 'S ha elátkozza százszor Pusztaszer,',\n",
       " 'Mégis gyõztes, mégis új és magyar.',\n",
       " 'LÉDA ASSZONY ZSOLTÁRAI',\n",
       " 'A MI GYERMEKÜNK',\n",
       " 'Bús szerelmünkbõl nem fakad',\n",
       " 'Szomorú lényünknek a mása,',\n",
       " 'Másokra száll a gyermekünk,',\n",
       " 'Ki lesz a vígak Messiása,',\n",
       " 'Ki majd miértünk is örül.',\n",
       " 'Ha jönnek az új istenek,',\n",
       " 'Ha jönnek a nem sejtett órák,',\n",
       " 'Valamikor, valamikor',\n",
       " 'Kipattannak a tubarózsák',\n",
       " 'S elcsattan hosszú csoda–csók.',\n",
       " 'Mások lesznek és mink leszünk:',\n",
       " 'Egy napvirág–szemû menyasszony',\n",
       " 'S egy napsugár–lelkû legény.',\n",
       " 'A tubarózsa illatozzon',\n",
       " 'S áldott legyen a mámoruk.',\n",
       " 'S áldott legyen, ki: te meg én,',\n",
       " 'Ki az övék, kiért mi sírtunk,',\n",
       " 'Kit forró lázunk eldobott,',\n",
       " 'Öleltetõnk, kit sohse bírtunk,',\n",
       " 'Ki másoké: a gyermekünk.',\n",
       " 'Kit napvirág és napsugár',\n",
       " 'Új igére, új dalra termett,',\n",
       " 'Áldott legyen, ki eljövend,',\n",
       " 'Az idegen, nagyálmú Gyermek,',\n",
       " 'Kit küldtek régi bánatok.',\n",
       " 'A VÁR FEHÉR ASSZONYA',\n",
       " 'A lelkem ódon, babonás vár,',\n",
       " 'Mohos, gõgös és elhagyott.',\n",
       " '(A két szemem, ugye, milyen nagy?',\n",
       " 'És nem ragyog és nem ragyog.)',\n",
       " 'Konganak az elhagyott termek,',\n",
       " 'A bús falakról rámered',\n",
       " 'Két nagy, sötét ablak a völgyre.',\n",
       " '(Ugye, milyen fáradt szemek?)',\n",
       " 'Örökös itt a lélekjárás,',\n",
       " 'A kripta–illat és a köd.',\n",
       " 'Árnyak suhognak a sötétben',\n",
       " 'S elátkozott had nyöszörög.',\n",
       " '(Csak néha, titkos éji órán',\n",
       " 'Gyúlnak ki e bús, nagy szemek.)',\n",
       " 'A fehér asszony jár a várban',\n",
       " 'S az ablakokon kinevet.',\n",
       " 'MERT ENGEM SZERETSZ',\n",
       " 'Áldott csodáknak',\n",
       " 'Tükre a szemed,',\n",
       " 'Mert engem nézett.',\n",
       " 'Te vagy a bölcse,',\n",
       " 'Mesterasszonya',\n",
       " 'Az ölelésnek.',\n",
       " 'Áldott ezerszer',\n",
       " 'Az asszonyságod,',\n",
       " 'Mert engem nézett,',\n",
       " 'Mert engem látott.',\n",
       " 'S mert nagyon szeretsz:',\n",
       " 'Nagyon szeretlek',\n",
       " 'S mert engem szeretsz:',\n",
       " 'Te vagy az Asszony,',\n",
       " 'Te vagy a legszebb.',\n",
       " 'A KÖNNYEK ASSZONYA',\n",
       " 'Bús arcát érzem szívemen',\n",
       " 'A könnyek asszonyának,',\n",
       " 'Rózsás, remegõ ujjai',\n",
       " 'Most a szivembe vájnak.',\n",
       " 'Érzem az illatát is ám',\n",
       " 'A rózsás, gyilkos ujjnak',\n",
       " 'S véres szívemre szomorún',\n",
       " 'A könnyek hullnak, hullnak.',\n",
       " 'Az ajka itt mar édesen,',\n",
       " 'A haja ide lebben,',\n",
       " 'Az egész asszony itt pusztít,',\n",
       " 'Itt, itt: az én szivemben.',\n",
       " 'Bosszút itt áll az életért,',\n",
       " 'Aknát itt ás a multnak.',\n",
       " 'Véres szívemre szomorún',\n",
       " 'A könnyek hullnak, hullnak.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:08:53.896921Z",
     "start_time": "2019-03-22T23:08:53.785239Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"data\", exist_ok=True)\n",
    "with io.open(\"data/ady_clean.txt\", mode='wt') as f:\n",
    "    for line in text:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:08:53.996010Z",
     "start_time": "2019-03-22T23:08:53.900321Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.vocab', 'model.pth', 'model.model', 'ady_clean.txt']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:08:54.086111Z",
     "start_time": "2019-03-22T23:08:54.000186Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SentPieceProcessor():\n",
    "    \n",
    "    TK_PAD = '<pad>'\n",
    "    TK_UNK = '<unk>'\n",
    "    TK_SOS = '<s>'\n",
    "    TK_EOS = '</s>'\n",
    "    \n",
    "    def __init__(self, model_path:str):\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(str(model_path))\n",
    "        self.id_unk = self.sp.unk_id()\n",
    "        self.tk_unk = self.sp.IdToPiece(self.id_unk)\n",
    "        self.tk_sos = self.sp.IdToPiece(1)\n",
    "        self.tk_eos = self.sp.IdToPiece(2)\n",
    "        self.tk_ws = self.sp.IdToPiece(3)\n",
    "        self.vocab_size = len(self.sp)\n",
    "        logger.info(f\"Initialized SentPieceProcessor from {model_path}\")\n",
    "    \n",
    "    def numericalize(self, tokens: List[str]) -> List[List[int]]:\n",
    "        if isinstance(tokens, str): tokens = [tokens]\n",
    "        ids =  [self.sp.EncodeAsIds(s) for s in tokens]\n",
    "        if len(ids) == 1: ids=ids[0]\n",
    "        return ids\n",
    "\n",
    "    def piecify(self, tokens: List[str]) -> List[List[str]]:\n",
    "        if isinstance(tokens, str): tokens = [tokens]\n",
    "        return [self.sp.EncodeAsPieces(s) for s in tokens]\n",
    "    \n",
    "    def textify(self, ids: List[int]) -> str:\n",
    "        if isinstance(ids, list) and isinstance(ids[0], np.generic): \n",
    "            ids = [int(x) for x in ids]\n",
    "        if not isinstance(ids, list) and not isinstance(ids[0], int):\n",
    "            raise TypeError(\"Argument `ids` has to be a list of integers.\")            \n",
    "        return self.sp.DecodeIds(ids)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = f\"SentPieceVocab (size: {self.vocab_size}\" \\\n",
    "            f\" 0:{self.tk_unk}, 1:{self.tk_sos}, 2:{self.tk_eos}, 3:{self.tk_ws})\"    \n",
    "        return s\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(cls, input_file:str, output_path:str='default', vocab_size:int=16000, \n",
    "               char_cov:float=1.0, model_type:str='unigram'):\n",
    "        \n",
    "        assert model_type in ['unigram', 'bpe', 'char', 'word']\n",
    "        assert 0 < char_cov <= 1\n",
    "        input_file = str(input_file)\n",
    "        output_file =  os.path.splitext(str(output_path))[0]\n",
    "        ext = '.model'\n",
    "        train_cmd = f\"--input={input_file} --model_prefix={output_file} --user_defined_symbols={cls.TK_PAD}\"\\\n",
    "                    f\" --vocab_size={vocab_size} --character_coverage={char_cov} --model_type={model_type}\"\n",
    "\n",
    "        logger.info(f\"Train command: {train_cmd}\")\n",
    "        logger.info(f\"Started training SentencePiece model...\")\n",
    "        ret = spm.SentencePieceTrainer.Train(train_cmd)\n",
    "        logger.info(f\"Exit code: {int(ret)}\")\n",
    "        return cls(output_file+ext)\n",
    "\n",
    "    @classmethod\n",
    "    def from_texts(cls, texts:List[str], output_path:str='default', vocab_size:int=16000,\n",
    "                   char_cov:float=1.0, model_type:str='unigram'):\n",
    "        \n",
    "        tmp_path = '/tmp/sentencepiece/'\n",
    "        os.makedirs(tmp_path, exist_ok=True)\n",
    "\n",
    "        with open(tmp_path+\"tmp.txt\", 'wt') as fin:\n",
    "            for line in texts:\n",
    "                fin.write(line+\"\\n\")\n",
    "        \n",
    "        spp = cls.from_file(tmp_path, output_path, vocab_size=vocab_size,\n",
    "                             char_cov=char_cov, model_type=model_type)\n",
    "        os.remove(tmp_path+\"tmp.txt\")\n",
    "        return spp\n",
    "    \n",
    "        \n",
    "    def _get_state():\n",
    "        pass\n",
    "    \n",
    "    def _set_state(state):\n",
    "        pass\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:09:03.013452Z",
     "start_time": "2019-03-22T23:08:54.090235Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-22 23:08:54,204 : INFO : Train command: --input=data/ady_clean.txt --model_prefix=data/model --user_defined_symbols=<pad> --vocab_size=32000 --character_coverage=0.999 --model_type=bpe\n",
      "2019-03-22 23:08:54,205 : INFO : Started training SentencePiece model...\n",
      "2019-03-22 23:09:02,989 : INFO : Exit code: 1\n",
      "2019-03-22 23:09:03,010 : INFO : Initialized SentPieceProcessor from data/model.model\n"
     ]
    }
   ],
   "source": [
    "processor = SentPieceProcessor.from_file(\"data/ady_clean.txt\", output_path=\"data/model\", \n",
    "                                         char_cov=0.999, vocab_size=32000, model_type='bpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:09:03.045124Z",
     "start_time": "2019-03-22T23:09:03.016110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11913, 5, 2173, 31931, 2923, 106, 12047, 156]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = processor.numericalize(\"Elmúlt a tél, Léda is elmúlt...\")\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:09:03.128258Z",
     "start_time": "2019-03-22T23:09:03.047324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elmúlt a tél, Léda is elmúlt...'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.textify(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:09:03.207394Z",
     "start_time": "2019-03-22T23:09:03.132122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<unk>', '<s>', '</s>', '<pad>')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.sp.IdToPiece(0), processor.sp.IdToPiece(1), processor.sp.IdToPiece(2), processor.sp.IdToPiece(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:09:03.294435Z",
     "start_time": "2019-03-22T23:09:03.211544Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn, optim, tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:09:03.390819Z",
     "start_time": "2019-03-22T23:09:03.298640Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class AdyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, texts, processor: SentPieceProcessor):\n",
    "        self.texts = texts\n",
    "        self.processor = processor\n",
    "                \n",
    "        self.itos = [self.processor.sp.IdToPiece(i) for i in range(self.processor.vocab_size)]\n",
    "        self.stoi = defaultdict(int,{v:k for k,v in enumerate(self.itos)}) \n",
    "        \n",
    "        self.vocab_size = self.processor.vocab_size\n",
    "        self.num_samples = len(texts)\n",
    "        self.max_len = max(len(t) for t in texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.numericalize(self.texts[idx])\n",
    "        x_len = len(seq)\n",
    "        pad = (0, self.max_len - x_len)\n",
    "        seq = F.pad(seq, pad, 'constant', value = self.stoi['<pad>'])\n",
    "        return {'x': seq[:-1], \n",
    "                'y': seq[1:],\n",
    "                'x_len': x_len}\n",
    "    def __len__(self): return self.num_samples\n",
    "    \n",
    "    def numericalize(self, text:str, sos_idx=1, eos_idx=2):\n",
    "        assert isinstance(text, str), \"text has to be a string\"\n",
    "        sequence =  [sos_idx] + self.processor.numericalize(text) + [eos_idx]\n",
    "        return torch.tensor(sequence)\n",
    "    \n",
    "    def textify(self, ids:list):\n",
    "        assert isinstance(ids, (list, torch.Tensor)), \"ids has to be an iterable (list/tensor)\"\n",
    "        if isinstance(ids, torch.Tensor): ids = list(ids.detach().cpu().numpy())\n",
    "        return self.processor.textify(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:09:11.933780Z",
     "start_time": "2019-03-22T23:09:03.395013Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-22 23:09:03,506 : INFO : Train command: --input=data/ady_clean.txt --model_prefix=data/model --user_defined_symbols=<pad> --vocab_size=32000 --character_coverage=0.999 --model_type=bpe\n",
      "2019-03-22 23:09:03,507 : INFO : Started training SentencePiece model...\n",
      "2019-03-22 23:09:11,876 : INFO : Exit code: 1\n",
      "2019-03-22 23:09:11,892 : INFO : Initialized SentPieceProcessor from data/model.model\n"
     ]
    }
   ],
   "source": [
    "processor = SentPieceProcessor.from_file(\"data/ady_clean.txt\", output_path=\"data/model\", \n",
    "                                         char_cov=0.999, vocab_size=32000, model_type='bpe')\n",
    "data = AdyDataset(text, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:09:11.960420Z",
     "start_time": "2019-03-22T23:09:11.935878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Leda elbujt'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = data.numericalize(\"Leda elbujt\")\n",
    "data.textify(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:09:12.037736Z",
     "start_time": "2019-03-22T23:09:11.962220Z"
    }
   },
   "outputs": [],
   "source": [
    "# bs = 4\n",
    "\n",
    "# dataloader = DataLoader(dataset=data, batch_size=bs, shuffle=True)\n",
    "\n",
    "# for batch in dataloader:\n",
    "    \n",
    "#     sorted_idx = np.array(batch['x_len']).argsort()[::-1].tolist()\n",
    "#     data_batch = {k:t[sorted_idx] for k,t in batch.items()}\n",
    "#     print(data_batch)\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T23:09:12.128551Z",
     "start_time": "2019-03-22T23:09:12.041266Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-15937874ecd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_batch' is not defined"
     ]
    }
   ],
   "source": [
    "x = data_batch['x']\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:50:04.708654Z",
     "start_time": "2019-03-23T08:50:04.655074Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "    \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size=128, hidden_size=128, num_layers=1, \n",
    "                 dropout_emb=0.2, dropout_lstm=0.0, tie_weights=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_emb)\n",
    "        self.encoder = nn.Embedding(vocab_size, embedding_size, padding_idx=3)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, bias=True, \n",
    "                           batch_first=True, dropout=dropout_lstm)\n",
    "        \n",
    "\n",
    "        self.decoder = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "        if tie_weights:\n",
    "            if embedding_size != hidden_size:\n",
    "                raise ValueError('When using the tied flag, nhid must be equal to emsize')\n",
    "            self.decoder.weight = self.encoder.weight\n",
    "        \n",
    "        self.init_weights()\n",
    "        self.embedding_size=embedding_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.num_layers=num_layers\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        weight = next(self.parameters())\n",
    "        return (weight.new_zeros(self.num_layers, bs, self.hidden_size),\n",
    "                weight.new_zeros(self.num_layers, bs, self.hidden_size))\n",
    "    \n",
    "    def forward(self, inputs, hidden=None, softmax=False):  \n",
    "        emb = self.dropout(self.encoder(inputs))\n",
    "        output, hidden = self.lstm(emb, hidden)\n",
    "        output = self.dropout(output)\n",
    "        bs, sl, hsz = output.shape\n",
    "        output = output.contiguous().view(bs * sl, hsz)\n",
    "        output = self.decoder(output).view(bs, sl, -1)\n",
    "        \n",
    "        return (F.softmax(output, dim=2), hidden) if softmax else (output, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:50:05.844681Z",
     "start_time": "2019-03-23T08:50:05.742691Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RNN(data.vocab_size, embedding_size=32, hidden_size=32, num_layers=2, tie_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T20:05:34.728657Z",
     "start_time": "2019-03-22T20:05:34.677081Z"
    }
   },
   "outputs": [],
   "source": [
    "b = next(iter(dataloader))\n",
    "inp, lens, targ = b['x'], b['x_len'], b['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T20:05:35.821413Z",
     "start_time": "2019-03-22T20:05:35.377853Z"
    }
   },
   "outputs": [],
   "source": [
    "output, hidden = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T20:05:35.886094Z",
     "start_time": "2019-03-22T20:05:35.828003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 81]), 32000, 81)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape, data.vocab_size, data.max_len-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T20:05:36.059889Z",
     "start_time": "2019-03-22T20:05:36.039049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 81]), torch.Size([4, 81, 32000]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T20:05:36.677969Z",
     "start_time": "2019-03-22T20:05:36.584011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32000])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, pred_inds = torch.max(output, dim=1)\n",
    "pred_inds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:50:42.516066Z",
     "start_time": "2019-03-23T08:50:42.464096Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "    \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size=128, hidden_size=128, num_layers=2, \n",
    "                 dropout_emb=0.1, dropout_lstm=0.25, tie_weights=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_emb)\n",
    "        self.encoder = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, bias=True, \n",
    "                           batch_first=True, dropout=dropout_lstm)\n",
    "        \n",
    "\n",
    "        self.decoder = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "        if tie_weights:\n",
    "            if embedding_size != hidden_size:\n",
    "                raise ValueError('When using the tied flag, nhid must be equal to emsize')\n",
    "            self.decoder.weight = self.encoder.weight\n",
    "        \n",
    "        self.init_weights()\n",
    "        self.embedding_size=embedding_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.num_layers=num_layers\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        weight = next(self.parameters())\n",
    "        return (weight.new_zeros(self.num_layers, bs, self.hidden_size),\n",
    "                weight.new_zeros(self.num_layers, bs, self.hidden_size))\n",
    "    \n",
    "    def forward(self, inputs, hidden=None, softmax=False):  \n",
    "        emb = self.dropout(self.encoder(inputs))\n",
    "        output, hidden = self.lstm(emb, hidden)\n",
    "        output = self.dropout(output)\n",
    "        bs, sl, hsz = output.shape\n",
    "        output = output.contiguous().view(bs * sl, hsz)\n",
    "        output = self.decoder(output).view(bs, sl, -1)\n",
    "        \n",
    "        return (F.softmax(output, dim=2), hidden) if softmax else (output, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T21:51:59.534963Z",
     "start_time": "2019-03-22T21:51:51.473979Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-22 21:51:51,514 : INFO : Train command: --input=data/ady_clean.txt --model_prefix=data/model --user_defined_symbols=<pad> --vocab_size=32000 --character_coverage=0.999 --model_type=bpe\n",
      "2019-03-22 21:51:51,516 : INFO : Started training SentencePiece model...\n",
      "2019-03-22 21:51:59,470 : INFO : Exit code: 1\n",
      "2019-03-22 21:51:59,487 : INFO : Initialized SentPieceProcessor from data/model.model\n"
     ]
    }
   ],
   "source": [
    "processor = SentPieceProcessor.from_file(\"data/ady_clean.txt\", output_path=\"data/model\", \n",
    "                                         char_cov=0.999, vocab_size=32000, model_type='bpe')\n",
    "data = AdyDataset(text, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:50:47.304942Z",
     "start_time": "2019-03-23T08:50:46.882782Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "bs = 40\n",
    "train_dl = DataLoader(dataset=data, batch_size=bs, shuffle=True)\n",
    "\n",
    "num_epochs = 200\n",
    "max_norm = .5\n",
    "\n",
    "lr = 0.03\n",
    "log_interval = 300\n",
    "\n",
    "embedding_size=256\n",
    "hidden_size=256\n",
    "num_layers=1\n",
    "tie_weights=True\n",
    "\n",
    "model = RNN(data.vocab_size, embedding_size=embedding_size, \n",
    "            hidden_size=hidden_size, num_layers=num_layers, tie_weights=True).to(device)\n",
    "\n",
    "opt_fn = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=data.stoi['<pad>'], reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:50:48.532819Z",
     "start_time": "2019-03-23T08:50:48.487190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (encoder): Embedding(32000, 256, padding_idx=0)\n",
       "  (lstm): LSTM(256, 256, batch_first=True, dropout=0.25)\n",
       "  (decoder): Linear(in_features=256, out_features=32000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-23T11:00:28.526Z"
    },
    "code_folding": [
     11
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67735034cd95495b9bd786dcb798cc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=756), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | loss  5.87 | ppl   355.55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e26a7f9e7b4a7793f52d2bedb8fde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=756), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | loss  5.89 | ppl   359.71\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c97cd359e84b5483642c1b7ca2741b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=756), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 | loss  5.88 | ppl   358.55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95aa1dc21f724c03ac5d521c43ddd384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=756), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 | loss  5.87 | ppl   356.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862699cdbbf341498915926d2d695211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=756), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 | loss  5.89 | ppl   360.66\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1dc2b88d0b40d7a9d1386aa6f6164b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=756), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 | loss  5.89 | ppl   359.93\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cce887127b5480295480567ed65410f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=756), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 | loss  5.89 | ppl   361.58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794817d1ac9840838a8b2e0b02474d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=756), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 | loss  5.88 | ppl   356.63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c824dad94b92446791e841b9e584a608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=756), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses=[]\n",
    "hidden = model.init_hidden(bs)\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for i, batch in enumerate(tqdm(train_dl)):\n",
    "            x, y = batch['x'].to(device), batch['y'].to(device)\n",
    "            x_len =  batch['x_len'].to(device)\n",
    "#             hidden = repackage_hidden(hidden)\n",
    "            model.zero_grad()\n",
    "            output, hidden = model(x, softmax=False)\n",
    "            _, pred = torch.max(output, dim=2)\n",
    "            loss = criterion(output.permute(0, 2, 1), y)\n",
    "            loss.backward()\n",
    "            if max_norm:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "\n",
    "            opt_fn.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "#             if i % log_interval == 0 and i > 0:\n",
    "#                 cur_loss = total_loss / log_interval\n",
    "#                 print(\"epoch {} | batch {}/{} | loss {:5.2f} | ppl {:8.2f}\".format(\n",
    "#                     epoch, i, len(train_dl), cur_loss, np.exp(cur_loss)))\n",
    "#                 total_loss = 0\n",
    "        epoch_loss = total_loss / len(train_dl)\n",
    "        print(\"epoch {} | loss {:5.2f} | ppl {:8.2f}\".format(epoch, epoch_loss, math.exp(epoch_loss)))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')\n",
    "\n",
    "finally:\n",
    "    torch.save(model.state_dict(), \"data/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:32:10.834621Z",
     "start_time": "2019-03-23T08:32:10.793116Z"
    }
   },
   "outputs": [],
   "source": [
    "inp = \"S a táj\"\n",
    "# inp = torch.tensor([data.stoi[t] for t in inp]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:34:17.994188Z",
     "start_time": "2019-03-23T08:34:17.938927Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-7ab4060b76d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hid' is not defined"
     ]
    }
   ],
   "source": [
    "input = data.numericalize(inp).unsqueeze(0).to(device)\n",
    "emb = model.encoder(input)\n",
    "out, hid = model.lstm(emb, hid)\n",
    "out = model.decoder(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:41:38.495759Z",
     "start_time": "2019-03-23T08:41:38.417001Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "_th_fill_ only supports a 0-dimensional value tensor, but got tensor with 1 dimension(s).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-054a17d59f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mword_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mword_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIdToPiece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#         outf.write(word + ('\\n' if i % 20 == 19 else ' '))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: _th_fill_ only supports a 0-dimensional value tensor, but got tensor with 1 dimension(s)."
     ]
    }
   ],
   "source": [
    "inp = \"S a táj\"\n",
    "\n",
    "hidden = model.init_hidden(1)\n",
    "vocab_size = data.vocab_size\n",
    "max_len=10\n",
    "temp = 0.9\n",
    "#\n",
    "# input = torch.randint(vocab_size, (1, 1), dtype=torch.long).to(device)\n",
    "\n",
    "input = data.numericalize(inp).long().unsqueeze(0).to(device)\n",
    "with torch.no_grad():  # no tracking history\n",
    "    for i in range(max_len):\n",
    "        output, hidden = model(input, hidden)\n",
    "        word_weights = output.squeeze().div(temp).exp().cpu()\n",
    "        word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "        input.fill_(word_idx)\n",
    "        word = data.processor.sp.IdToPiece(int(word_idx.item()))\n",
    "#         outf.write(word + ('\\n' if i % 20 == 19 else ' '))\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:40:10.673511Z",
     "start_time": "2019-03-23T08:40:10.631280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:20:26.114121Z",
     "start_time": "2019-03-23T08:20:26.064770Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_example(model, stoi, itos, temperature=1.0,  max_len=100, hidden_state=None):\n",
    "\n",
    "    start_token, start_idx = '<s>', 1\n",
    "    \n",
    "    # Start state.\n",
    "    inputs = torch.tensor(stoi[start_token]).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    sentence = [start_token]\n",
    "    i = 0\n",
    "    while i < max_len and sentence[-1] not in ['</s>', '<pad>']:\n",
    "        i += 1\n",
    "        \n",
    "        embedded = model.encoder(inputs)\n",
    "        output, hidden_state = model.lstm(embedded, hidden_state)\n",
    "\n",
    "        batch_size, sequence_len, hidden_size = output.shape\n",
    "        output = output.contiguous().view(batch_size * sequence_len, hidden_size)    \n",
    "        output = model.decoder(output).view(batch_size, sequence_len, -1).squeeze(0)\n",
    "        #_, prediction = torch.max(F.softmax(output, dim=2), dim=2)\n",
    "        \n",
    "        word_weights = output.div(temperature).exp().cpu()\n",
    "        if len(word_weights.shape) > 1:\n",
    "            word_weights = word_weights[-1] # Pick the last word.    \n",
    "        \n",
    "        word_idx = torch.multinomial(word_weights, 1).view(-1)\n",
    "        \n",
    "        sentence.append(itos[int(word_idx)])\n",
    "        \n",
    "        inputs = tensor([stoi[word] for word in sentence]).unsqueeze(0).to(device)\n",
    "        \n",
    "    print(''.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:27:10.522443Z",
     "start_time": "2019-03-23T08:27:10.264737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>▁A▁Halált,</s>\n",
      "<s>▁Mi–voltom,</s>\n",
      "<s>▁S▁ha▁a▁sok▁világ,</s>\n",
      "<s>▁S▁nem,▁magyar▁a▁legszebb</s>\n",
      "<s>▁S▁nem▁a▁Sors▁régi</s>\n",
      "<s>▁S▁egy–e,▁a▁messze,</s>\n",
      "<s>▁A▁nagy,▁szent▁tervelõk</s>\n",
      "<s>▁S▁a▁magyar,</s>\n",
      "<s>▁S▁ha▁én,▁hogy,</s>\n",
      "<s>▁Egy▁a▁magyar.</s>\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    generate_example(model, data.stoi, data.itos, max_len=50, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T08:18:32.268188Z",
     "start_time": "2019-03-23T08:18:32.224079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A VÁR FEHÉR ASSZONYA',\n",
       " 'A lelkem ódon, babonás vár,',\n",
       " 'Mohos, gõgös és elhagyott.',\n",
       " '(A két szemem, ugye, milyen nagy?',\n",
       " 'És nem ragyog és nem ragyog.)',\n",
       " 'Konganak az elhagyott termek,',\n",
       " 'A bús falakról rámered',\n",
       " 'Két nagy, sötét ablak a völgyre.',\n",
       " '(Ugye, milyen fáradt szemek?)',\n",
       " 'Örökös itt a lélekjárás,',\n",
       " 'A kripta–illat és a köd.',\n",
       " 'Árnyak suhognak a sötétben',\n",
       " 'S elátkozott had nyöszörög.',\n",
       " '(Csak néha, titkos éji órán',\n",
       " 'Gyúlnak ki e bús, nagy szemek.)',\n",
       " 'A fehér asszony jár a várban',\n",
       " 'S az ablakokon kinevet.',\n",
       " 'MERT ENGEM SZERETSZ',\n",
       " 'Áldott csodáknak',\n",
       " 'Tükre a szemed,',\n",
       " 'Mert engem nézett.',\n",
       " 'Te vagy a bölcse,',\n",
       " 'Mesterasszonya',\n",
       " 'Az ölelésnek.',\n",
       " 'Áldott ezerszer',\n",
       " 'Az asszonyságod,',\n",
       " 'Mert engem nézett,',\n",
       " 'Mert engem látott.',\n",
       " 'S mert nagyon szeretsz:',\n",
       " 'Nagyon szeretlek',\n",
       " 'S mert engem szeretsz:',\n",
       " 'Te vagy az Asszony,',\n",
       " 'Te vagy a legszebb.',\n",
       " 'A KÖNNYEK ASSZONYA',\n",
       " 'Bús arcát érzem szívemen',\n",
       " 'A könnyek asszonyának,',\n",
       " 'Rózsás, remegõ ujjai',\n",
       " 'Most a szivembe vájnak.',\n",
       " 'Érzem az illatát is ám',\n",
       " 'A rózsás, gyilkos ujjnak',\n",
       " 'S véres szívemre szomorún',\n",
       " 'A könnyek hullnak, hullnak.',\n",
       " 'Az ajka itt mar édesen,',\n",
       " 'A haja ide lebben,',\n",
       " 'Az egész asszony itt pusztít,',\n",
       " 'Itt, itt: az én szivemben.',\n",
       " 'Bosszút itt áll az életért,',\n",
       " 'Aknát itt ás a multnak.',\n",
       " 'Véres szívemre szomorún',\n",
       " 'A könnyek hullnak, hullnak.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH deepfred-gpu-1-0-6 deepfred-gpu-1-0-6",
   "language": "",
   "name": "rik_ssh_deepfred_gpu_1_0_6_deepfredgpu106"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
